{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karate Club Graph Clustering\n",
    "In this notebook the GFlowNet is applied to the famous Karate Club Graph. Note that training is rather computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from Core.Core import GraphNet, GraphNetNodeOrder, check_gpu, GibbsSampleStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether Pytorch can use the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is not available\n"
     ]
    }
   ],
   "source": [
    "check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training will occur using a set number of samples, every 'epoch_interval' the network will be used to draw this number of samples to estimate the empirical distribution. The number of epochs to continue training for must also be set. The boolean variable 'node_order' specifies whether to train the network using a fixed node order, which is randomly generated every forward pass through the graph. 'GibbsStart' specifies whether to draw the initial sample from the GibbsSampler. The final variable to set is the 'GibbsProportion' which specifies which proportion of the samples to continue training on are from the GibbsSampler initialised using a sample from the previous samples from the GFlowNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to set:\n",
    "nSamples = 10   # Must be greater than 1\n",
    "epochInterval = 1\n",
    "minEpochs = 0   # Left in there for continuing training\n",
    "maxEpochs = 2\n",
    "nodeOrder = True\n",
    "GibbsStart = False\n",
    "GibbsProportion = .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampled clusterings are saved in the 'Data' folder and the weights in the 'Weights' folder. Each filename consists of a string of the structure seen below, one can add a prefix to distinguish between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = ''\n",
    "nodeOrderString = '_o' if nodeOrder else ''\n",
    "filepathSamples = f'Data/{prefix}Karate{minEpochs}_{maxEpochs}_{nSamples}{nodeOrderString}_Samples_'\n",
    "filepathWeights = f'Weights/{prefix}Karate{minEpochs}_{maxEpochs}_{nSamples}{nodeOrderString}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is loaded and the network is initialised. Here the number of hidden layers and the number of hidden units is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLayers = 5\n",
    "nHidden = 64\n",
    "\n",
    "Adj_karate = torch.tensor(pd.read_csv(\"Data/Adj_karate.csv\", header=None, dtype=int).to_numpy())\n",
    "n = Adj_karate.shape[0]\n",
    "net = GraphNetNodeOrder(nNodes=n, nLayers=nLayers, nHidden=nHidden) if nodeOrder else GraphNet(nNodes=n)\n",
    "net.save(prefix=filepathWeights, postfix=str(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the initial sample is drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\GFlowNets\\Core\\Core.py:701: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  clustering_list[node_index] = torch.tensor(cluster_index_chosen + 1, dtype=torch.float32)\n",
      "Sampling: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "X1 = GibbsSampleStates(Adj_karate, nSamples=nSamples, N=n) if GibbsStart \\\n",
    "        else net.sample_forward(Adj_karate, nSamples=nSamples, timer=True)\n",
    "torch.save(X1, filepathSamples + f'{0}.pt')\n",
    "nGibbs = int(nSamples * GibbsProportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the training loop! Here the network's weights and the samples drawn each iteration are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\GFlowNets\\Core\\Core.py:858: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = torch.t_copy(torch.tensor(C_in, dtype=torch.int64))\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 23.26it/s]\n",
      "C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\GFlowNets\\Core\\Core.py:1383: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tempSamples = Gibbs_sample_torch(torch.tensor(adjacency_matrix, dtype=torch.float32), T=nSamples * 2, z=z)\n",
      "Gibbs Sampling: 100%|██████████| 12/12 [00:00<00:00, 35.75it/s]\n",
      "C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\GFlowNets\\Core\\Core.py:1387: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X1[i] = torch.concat((adjacency_matrix.flatten(), torch.tensor(sample.flatten())))\n",
      "Sampling: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 37.03it/s]\n",
      "Gibbs Sampling: 100%|██████████| 12/12 [00:00<00:00, 36.84it/s]\n",
      "Sampling: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, ((maxEpochs - minEpochs) // epochInterval) + 1):\n",
    "        net.train(X1, epochs=epochInterval)  # Train an extra epoch interval\n",
    "        # Take a sample from the GFlowNet part of the previous samples:\n",
    "        z = X1[nGibbs:][torch.randint(nSamples - nGibbs, (1,))][0][net.n_nodes ** 2:].reshape((net.n_nodes, net.n_nodes))\n",
    "        z = net.get_clustering_list(z)[0].reshape((-1, 1))\n",
    "        # Sample again:\n",
    "        gibbsSamples = GibbsSampleStates(Adj_karate, nSamples=nGibbs, N=net.n_nodes, z=z)\n",
    "        gflowSamples = net.sample_forward(Adj_karate,\n",
    "                                          nSamples=nSamples - nGibbs,\n",
    "                                          timer=True,\n",
    "                                          saveFilename=filepathSamples + f'{i * epochInterval}')\n",
    "        X1 = torch.concat((gibbsSamples, gflowSamples), dim=0)\n",
    "        net.save(prefix=filepathWeights, postfix=str(epochInterval * i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
